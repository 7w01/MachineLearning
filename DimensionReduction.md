# 降维  (Dimension reduction)



## 多维缩放(MDS)

**原理**是使不同样本之间的**距离**，在**降维后不改变**

原始空间的距离矩阵为$D\in R^{m\times m}$，其第$i$行第$j$列的元素$dist_{ij}$为样本$x_i$到$x_j$的距离

我们的目标是获得样本在$d^{'}$维空间的表示$Z \in R^{d^{'} \times m}$，$d\leq d^{'}$，且任意两个样本在$d^{'}$维空间中的距离等于原始空间中的距离，即
$$
||z_i-z_j||=dist_{ij}
\tag{1}
$$
令$B=Z^TZ\in R^{m\times m}$，$b_{ij}=z^T_iz_j$，有
$$
dist^2_{ij}=||z_i||^2+||z_j||^2-2z^T_iz_j\\
=b_{ii}+b_{jj}-2b_{ij}
\tag{2}
$$
为了便于讨论，令降维后的$Z$**中心化**，即
$$
\sum^m_{i=1}z_i=0
\tag{3}
$$
显然，矩阵$B$的各行和或各列和均为0，则
$$
\sum^m_{i=1}dist_{ij}=tr(B)+mb_{jj}\\
\sum^m_{j=1}dist_{ij}=tr(B)+mb_{ii}\\
\sum^m_{i=1}\sum^m_{j=1}dist_{ij}=2mtr(B)
\tag{4}
$$
令
$$
dist^2_{i.}=\frac{1}{m}\sum^m_{j=1}dist^2_{ij}\\
dist^2_{.j}=\frac{1}{m}\sum^m_{i=1}dist^2_{ij}\\
dist^2_{..}=\frac{1}{m^2}\sum^m_{i=1}\sum^m_{j=1}dist^2_{ij}
\tag{5}
$$
可得
$$
b_{ij}=-\frac{1}{2}(dist^2_{ij}-dist^2_{i.}-dist^2_{.j}+dist^2_{..})
\tag{6}
$$
由此可求得矩阵$B$

$B$为实对称矩阵，可做**特征值分解**，$B=V^T\Lambda V$，则样本在$d^{'}$维空间的表示
$$
Z=\Lambda^{\frac{1}{2}}V
\tag{7}
$$
在现实任务中，降维后的距离和原始距离仅需尽可能的相近，故选择较大的特征值来**近似**即可



## 线性降维



基于线性变换来进行降维
$$
Z=W^TX
\tag{8}
$$
$Z$为样本在$d^{'}$维空间的表示，$W\in R^{d^{'}\times m}$为线性变换矩阵，$X$为样本矩阵



### 主成分分析(PCA)



用超平面对所有样本进行恰当的表达，需要考虑

​	1.**最近重构性：**样本到这个超平面的距离都足够近

​	2.**最大可分性：**样本在这个超平面的投影都尽可能分开



#### 基于最近重构性推导



假定样本进行了去中心化，空间正交坐标系为$W=(\omega_1,\omega_2,...,\omega_d)$，其中$\omega_i$是标准正交基向量，去掉部分向量即为超平面的基向量, $||\omega_i||^2=1$，$\omega^T_i\omega_j=0$，样本在超平面的投影坐标为$z_i=(z_{i1},z_{i2},...,z_{id^{'}},0,...)^T$，则基于投影重构的样本
$$
\hat{x_i}=\sum^{d^{'}}_{j=1}z_{ij}\omega_j=Wz_i
\tag{9}
$$
原样本与重构后的样本之间的距离为
$$
\sum^m_{i=1}||\hat{x_i}-x_i||^2_2=\sum^m_{i=1}z^T_iz_i-2\sum^m_{i=1}z^T_iW^Tx_i+const\\
\propto -tr(W^T(\sum^m_{i=1}x_ix^T_i)W)
\tag{10}
$$
**最小化距离**，即
$$
\mathop{min}_{W}\quad -tr(W^TXX^TW)\\
s.t.\quad W^TW=I
\tag{11}
$$


#### 基于最大可分性推导



样本在超平面的投影为$W^Tx_i$，若所有投影点都尽可能的分开，则应使投影后样本点的**方差最大化**，即$\sum_iW^Tx_ix^T_iW$，优化目标为
$$
\mathop{max}_{W}\quad tr(W^TXX^TW)\\
s.t.\quad W^TW=I
\tag{12}
$$
显然，通过两种方式推导得到的**优化目标一致**



#### PCA的解



对(12)式使用**拉格朗日乘子法**，得
$$
XX^T\omega_i=\lambda_i\omega_i
\tag{13}
$$
形式正好符合特征值分解，故对$XX^T$做**特征值分解**，将求得的特征值排序：$\lambda_1\geq \lambda_2\geq...\geq \lambda_d$，取前$d^{'}$个特征值对应的特征向量构成$W^*=(\omega_1,\omega_2,...,\omega_{d^{'}})$​



#### 总流程



1.对样本中心化

2.计算样本协方差矩阵$XX^T$

3.对协方差矩阵做特征值分解

4.取最大的$d^{'}$个特征值对应的特征向量$W^*=(\omega_1,\omega_2,...,\omega_{d^{'}})$​

5.输出投影在超平面的坐标$(W^*)^Tx_i$



PCA降维舍弃的特征向量往往与噪声有关，在一定程度上能起到**去噪**的作用



### 核化线性降维



在任务中，可能从二位区域采样后以S形曲面嵌入三维空间中，若直接使用线性降维方法则丢失了原本的"**本真**"二维结构，故可能需要用到**非线性映射**












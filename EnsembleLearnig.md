# 集成学习(Ensemble Learning)

集成学习的一般结构：先产生一组**个体学习器**，再用某种策略将他们结合起来

用相同算法训练学习器组，称为**同质集成**，称个体学习器为**基学习器**

用不同算法训练学习器组，称为**异质集成**，称个体学习器为**组件学习器**



集成学习常可获得比单一学习器显著优越的泛化性能，对“弱学习器”尤为明显，故集成学习大多针对弱学习器进行. 但在实际情况中，希望使用较少的个体学习器，故往往会用比较强的学习器



集成学习大致可分为两大类：个体学习器间存在强依赖关系、必须串行生成的**序列化方法**

​						  个体学习器间不存在强依赖关系、可同时生成的**并行化方法**



## 性能分析

每个基学习器有
$$
P(h_i(X)\neq f(x))=\epsilon
$$
使用简单投票法
$$
H(x)=sign(\sum^{T}_{i=1}h_i(x))
$$
假设基分类器的错误率相互独立
$$
P(H(X)\neq f(x))\le exp(-\frac{1}{2}T(1-2\epsilon)^2)
$$
上式子显示，随着集成数目增大，集成的错误率将指数下降，最总趋于零

但是错误率互相独立的假设不可能成立，因为基学习器都基于同一数据集训练得到，故产生**好而不同**的个体学习器是集成学习的核心！


## 序列化方法

**Boosting**族算法机制：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，使得先前基学习器做错的样本在后续受到更多的关注，然后基于调整后的样本分布训练下一个基学习器



### AdaBoost

“加性模型”，即基学习器的线性组合
$$
H(x)=\sum^{T}_{t=1}\alpha_th_t(X)
$$
第一个基学习器$h_1$学习初始数据分布而得；此后迭代生成$h_t$和$\alpha_t$，当$h_t$基于$D_t$产生后，该基分类器的权重$\alpha_t$应使得最小化指数损失函数
$$
l_{exp}(\alpha_th_t|D_t)=E_{x\~D}[e^{-f(x)\alpha_th_t(x)}]\\
=E_{x\~D}[e^{-\alpha_t}I(f(x)=h_t(x))+e^{\alpha_t}I(f(x)\neq h_t(x))]\\
=e^{-\alpha_t}P_{x\~D_t}(f(x)=h_t(x))+e^{\alpha_t}P_{x\~D_t}(f(x)\neq h_t(x))\\
=e^{-\alpha_t}(1-\epsilon_t)+e^{\alpha_t}\epsilon_t
$$
对$\alpha_t$求偏导，令式子等于零，得
$$
\alpha_t=\frac{1}{2}ln(\frac{1-\epsilon_t}{\epsilon_t})
$$
 AdaBoost算法在获得$H_{t-1}$后样本分布将进行调整，使下一轮的基学习器$h_t$能纠正$H_{t-1}$的一些错误
$$
l_{exp}(H_{t-1}+h_t|D)=E_{x\~D}[e^{-f(x)(H_{t-1}(x)+h_t(x))}]
$$
使用泰勒展开近似
$$
=E_{x\~D}[e^{-f(x)H_{t-1}(x)}(1-f(x)h_t(x)+\frac{f^2(x)h^2_t(x)}{2})]\\
=E_{x\~D}[e^{-f(x)H_{t-1}(x)}(1-f(x)h_t(x)+\frac{1}{2})]
$$
于是，理想的基学习器
$$
h_t(x)=argmin_hl_{exp}(H_{t-1}+h_t|D)\\
=argmin_hE_{x\~D}[e^{-f(x)H_{t-1}(x)}(1-f(x)h_t(x)+\frac{1}{2})]\\
=argmax_hE_{x\~D}[e^{-f(x)H_{t-1}(x)}f(x)h_t(x)]\\
=argmax_hE_{x\~D}[\frac{e^{-f(x)H_{t-1}(x)}}{E_{x\~D}[e^{-f(x)H_{t-1}(x)}]}f(x)h_t(x)]\\
$$
令新分布
$$
D_t(x)=\frac{D(x)e^{-f(x)H_{t-1}(x)}}{E_{x\~D}[e^{-f(x)H_{t-1}(x)}]}
$$

$$
h_t(x)=argmax_hE_{x\~D_t}[f(x)h(x)]
$$

由于 $f(x)h(x)=1-2I(f(x)\neq h(x))$
$$
h_t(x)=argmin_hE_{x\~D_t}[I(f(x)\neq h(x))]
$$
可见，理想的$h_t$将在分布$D_t$下最小化分类误差



**输入：**训练集D={$(x_1,y_1),(x_2,y_2),...,(x_m,y_m)$}

​		基学习算法E

​		训练轮数T

**过程：**

​	$D_1(x)=1/m$

​	**for** t=1,2,...,T

​		$h_t=E(D,D_t)$

​		$\epsilon_t=P_{x\~D_t}(h_t(x)\neq f(x))$

​		**if** $\epsilon_t\gt 0.5$

​			**break**

​		$\alpha_t=\frac{1}{2}ln(\frac{1-\epsilon_t}{\epsilon_t})$

​		$D_{t+1}(x)=\frac{D_t(x)e^{-\alpha_t f(x)h_t(x)}}{Z_t(归一项)}$

**输出：**$H(x)=sign(\sum^T_{t=1}\alpha_th_t(x))$



**Adaboost只能用于二分类**



## 并行化方法

集成中的个体学习器独立在现实中无法做到，但可以使基学习器有较大的差异，一种做法是对训练样本进行处理



### Bagging (Bootstrap AGGregatING)

基于自助采样法，放回地随机取m个样本，初始训练集中约有1/e的样本未被采样

照此方法训练T个基学习器，然后再将这些基学习器结合



对简单任务通常使用简单投票法，回归任务使用简单平均法



**输入：**训练集D={$(x_1,y_1),(x_2,y_2),...,(x_m,y_m)$}

​		基学习算法E

​		训练轮数T

**过程：**

​	**for** t=1,2,...,T

​		$h_t=E(D,D_bs)$

**输出：**$H(x)=argmax_y\sum^T_{t=1}I(h_t(x)=y)$



**Bagging可直接用于多分类任务**，且高效



### 随机森林(Random Forest)

是Bagging的一个扩展变体，在以决策树为基学习器的构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择

具体来说马，对于基决策树的每个结点，先从属性集合中随机选择k个属性，然后再从这个子集中选择一个最优属性用于划分

**随机森林简单、易于实现、计算开销小，在很多现实任务中展现出强大的性能**















